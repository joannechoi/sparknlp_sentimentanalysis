{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.param import *\n",
    "from pyspark.ml.tuning import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import * \n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"dateAdded\", StringType(), True),\n",
    "    StructField(\"dateUpdated\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"asins\", StringType(), True),\n",
    "    StructField(\"brand\", StringType(), True),\n",
    "    StructField(\"categories\", StringType(), True),\n",
    "    StructField(\"primaryCategories\", StringType(), True),\n",
    "    StructField(\"imageURLs\", StringType(), True),\n",
    "    StructField(\"keys\", StringType(), True),\n",
    "    StructField(\"manufacturer\", StringType(), True),\n",
    "    StructField(\"manufacturerNumber\", StringType(), True),\n",
    "    StructField(\"reviews.date\", StringType(), True),\n",
    "    StructField(\"reviews.dateAdded\", StringType(), True),\n",
    "    StructField(\"reviews.dateSeen\", StringType(), True),\n",
    "    StructField(\"reviews.doRecommend\", StringType(), True),\n",
    "    StructField(\"reviews.id\", StringType(), True),\n",
    "    StructField(\"reviews.numHelpful\", StringType(), True),\n",
    "    StructField(\"reviews.rating\", IntegerType(), True),\n",
    "    StructField(\"reviews.sourceURLs\", StringType(), True),\n",
    "    StructField(\"reviews.text\", StringType(), True),\n",
    "    StructField(\"reviews.title\", StringType(), True),\n",
    "    StructField(\"reviews.username\", StringType(), True),\n",
    "    StructField(\"sourceURLs\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .schema(schema)\\\n",
    "    .csv(\"/Users/joanne/Documents/School/nlp_data/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
    "\n",
    "for name in raw_data.schema.names:\n",
    "      raw_data = raw_data.withColumnRenamed(name, name.replace('.', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, dateAdded: string, dateUpdated: string, name: string, asins: string, brand: string, categories: string, primaryCategories: string, imageURLs: string, keys: string, manufacturer: string, manufacturerNumber: string, reviews_date: string, reviews_dateAdded: string, reviews_dateSeen: string, reviews_doRecommend: string, reviews_id: string, reviews_numHelpful: string, reviews_rating: int, reviews_sourceURLs: string, reviews_text: string, reviews_title: string, reviews_username: string, sourceURLs: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label column based on user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 4 stars and 5 stars as 1, 3 stars as 0, and 2 stars and 1 star as 0;\n",
    "\n",
    "#data = raw_data\\\n",
    "#    .withColumn('label', when(raw_data.reviews_rating > 3, '1')\\\n",
    "#    .when(raw_data.reviews_rating == 3, '0')\\\n",
    "#    .otherwise('-1'))\\\n",
    "#    .select('name','reviews_text','reviews_rating','label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 4 stars and 5 stars as 1, and rest as 0  - do we want to remove the  star ratings?\n",
    "reviews = raw_data\\\n",
    "    .withColumn('label', when(raw_data.reviews_rating > 3, '1')\\\n",
    "    .otherwise('0'))\\\n",
    "    .select('name','reviews_text','reviews_rating','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the label data from StringType to IntegerType\n",
    "reviews = reviews\\\n",
    "    .withColumn('label', reviews['label'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, reviews_text: string, reviews_rating: int, label: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print schema and cache the dataframe\n",
    "reviews.printSchema\n",
    "reviews.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create index column - not sure if this is needed\n",
    "#reviews = spark.createDataFrame(data.toPandas().reset_index())\n",
    "#reviews.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-----+\n",
      "|                name|reviews_rating|label|\n",
      "+--------------------+--------------+-----+\n",
      "|All-New Fire HD 8...|             5|    1|\n",
      "|Fire Kids Edition...|             3|    0|\n",
      "|\"Amazon Echo Show...|             4|    1|\n",
      "|All-New Fire HD 8...|             3|    0|\n",
      "|\"Amazon Echo Show...|             5|    1|\n",
      "+--------------------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preview data\n",
    "reviews.select('name','reviews_rating','label').distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    reviews_rating|\n",
      "+-------+------------------+\n",
      "|  count|              5000|\n",
      "|   mean|            4.5968|\n",
      "| stddev|0.7318038448747551|\n",
      "|    min|                 1|\n",
      "|    max|                 5|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.select('reviews_rating').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|reviews_rating|count|\n",
      "+--------------+-----+\n",
      "|             1|   63|\n",
      "|             2|   54|\n",
      "|             3|  197|\n",
      "|             4| 1208|\n",
      "|             5| 3478|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.select('reviews_rating')\\\n",
    "    .groupBy('reviews_rating')\\\n",
    "    .count()\\\n",
    "    .orderBy('reviews_rating', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+\n",
      "|reviews_rating|label|count|\n",
      "+--------------+-----+-----+\n",
      "|             1|    0|   63|\n",
      "|             2|    0|   54|\n",
      "|             3|    0|  197|\n",
      "|             4|    1| 1208|\n",
      "|             5|    1| 3478|\n",
      "+--------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.select('reviews_rating','label')\\\n",
    "    .groupBy('reviews_rating','label')\\\n",
    "    .count()\\\n",
    "    .orderBy('reviews_rating', ascending=True)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the sentiment analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data - may need to change the split\n",
    "train_set, test_set = reviews.randomSplit([0.9, 0.1], seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "tokenizer = RegexTokenizer(inputCol=\"reviews_text\", outputCol=\"token\").setPattern(\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"token\", outputCol=\"stopwordsremoved\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"stopwordsremoved\", outputCol='hashingTF')\n",
    "idf = IDF(inputCol='hashingTF', outputCol=\"IDF\", minDocFreq=5)\n",
    "\n",
    "# label\n",
    "label_stringIdx = StringIndexer(inputCol = \"label\", outputCol = \"StringIndexer\")\n",
    "\n",
    "# pipe\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashtf, idf, label_stringIdx])\n",
    "model = pipeline.fit(train_set)\n",
    "train_df = model.transform(train_set)\n",
    "test_df = model.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|reviews_rating|StringIndexer|\n",
      "+--------------+-------------+\n",
      "|             1|          1.0|\n",
      "|             2|          1.0|\n",
      "|             3|          1.0|\n",
      "|             4|          0.0|\n",
      "|             5|          0.0|\n",
      "+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verify the pipeline\n",
    "train_df.select('reviews_rating','StringIndexer')\\\n",
    "    .distinct()\\\n",
    "    .orderBy('reviews_rating', ascending=True)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|stopwordsremoved                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[nice, next, step, alexa, repertoire, easy, set, use]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|[already, 2, bb, big, sale, price, couldn, order, fast, enough, see, nest, cameras, another, 5, product, make, video, calls, show, owners, voice, calls, anyone, else, except, 911, whole, host, skills, added, almost, daily, regret, replacing, 2, remaining, echo, dots, sale, won, make, mistake, next, big, sale, also, received, 2, home, assistants, included, free, bonuses, buying, couple, things, thought, fair, compare, two, disregarging, video, aspects, show, amazon, shows, dots, echos, like, comparing, lambourgini, 68, vw, bug, setting, things, like, expression, heard, kid, easier, fallin, log, near, dangerous]|\n",
      "|[despite, less, friendly, price, point, get, sale, amazon, item, well, designed, delivers, promises, hype, product, description, emphasis, item, show, surprise, sound, quality, compare, echo, want, convenience, voice, controlled, screen, phone, product, delivers, value, even, greater, paired, smart, devices, security, cams, another, added, bonus, comes, friends, family, also, show, drop, essentially, visual, phone, calls, great, checking, elderly, family, require, technically, savvy]                                                                                                                                 |\n",
      "|[time, searching, replacement, sony, dash, support, discontinued, recently, sure, bedside, smart, alarm, clock, primary, goal, echo, show, fit, bill, nicely, first, echo, purchase, multiple, echo, hue, lights, great, system, around]                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|[fun, easy, use, music, sounds, great, set, timers, reminders, sync, calendar, m, giving, one, gift, daughter, video, chat, drop, time]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select('stopwordsremoved').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the logistic regression model\n",
    "log_reg = LogisticRegression(labelCol=\"label\", featuresCol=\"hashingTF\", \n",
    "                        maxIter=10, regParam=0.01)\n",
    "lr_model = log_reg.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+\n",
      "|    stopwordsremoved|prediction|label|\n",
      "+--------------------+----------+-----+\n",
      "|[echo, show, grea...|       1.0|    1|\n",
      "|[perfect, upgrade...|       1.0|    1|\n",
      "|[absolutely, love...|       1.0|    1|\n",
      "|[addition, system...|       1.0|    1|\n",
      "|[addition, system...|       1.0|    1|\n",
      "|[another, great, ...|       1.0|    1|\n",
      "|[good, echo, adde...|       1.0|    1|\n",
      "|[first, concerned...|       1.0|    1|\n",
      "|[awesome, far, us...|       1.0|    1|\n",
      "|[best, item, ever...|       1.0|    1|\n",
      "+--------------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the logistic regression model\n",
    "lr_predict = lr_model.transform(test_df)\n",
    "lr_final = lr_predict.select(\"stopwordsremoved\", \"prediction\", \"label\")\n",
    "lr_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Prediction: 478 , Total: 498 , Accuracy Rate: 0.9598393574297188\n"
     ]
    }
   ],
   "source": [
    "lr_correct = lr_final\\\n",
    "    .filter(lr_final.prediction == lr_final.label)\\\n",
    "    .count()\n",
    "\n",
    "lr_total = lr_final.count()\n",
    "\n",
    "print(\"Correct Prediction:\", lr_correct, \", Total:\", lr_total, \n",
    "      \", Accuracy Rate:\", lr_correct/lr_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
